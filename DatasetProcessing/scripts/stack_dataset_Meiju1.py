import sys
sys.path.append('./')
from src.processing.convert import tif_to_npy_folder
from src.processing.background_black import smart_image_converter
from src.processing.stack_data import stack_npy_files, split_npy_files_threaded
from src.processing.crop import crop_with_repetition, crop_with_repetition_and_convert_delete, crop_with_repetition_and_save_skip_log
from src.utils.email_utils import send_email
from src.utils.file_io import remove_folder, rename_files
from src.processing.split import split_dataset
import os
import argparse
from tqdm import tqdm
from datetime import datetime
import numpy as np
from collections import defaultdict
from typing import Dict, List, Tuple
import json
from calc_mean_std import calc_mean_and_std, visualize_feature
import shutil
from osgeo import gdal
from PIL import Image
import concurrent.futures # å¯¼å…¥å¹¶å‘å¤„ç†æ¨¡å—

def create_dataset_image(image_folder, output_folder, resolution, crop_size=640, repetition_rate=0.1, tif_shuffix = ".tif", shuffix=".npy", skip_log="conversion_skip.json"):
    # å…ˆè£å‰ªTif(Image_Tif)å’Œæ ‡ç­¾æ–‡ä»¶å¤¹(Label_Tif)
    # åˆ é™¤å¤šä½™çš„å›¾ç‰‡(Image_Tif)å¹¶è½¬æ¢ä¸ºnpyæ–‡ä»¶(Image_Npy)å’Œpngæ–‡ä»¶(Label_Png)
    # æœ€åŽåˆ é™¤æ ‡ç­¾å’Œtifæ–‡ä»¶å¤¹(Image_Tif, Label_Tif)
    image_tif_folder = "Image_Tif"
    # label_tif_folder = "Label_Tif"
    image_npy_folder = "Image_Npy"
    # label_png_folder = "Label_Png"
    image_tif_folder = os.path.join(output_folder, image_tif_folder)
    # label_tif_folder = os.path.join(output_folder, label_tif_folder)
    image_npy_folder = os.path.join(output_folder, image_npy_folder)
    # label_png_folder = os.path.join(output_folder, label_png_folder)

    os.makedirs(image_tif_folder, exist_ok=True)
    os.makedirs(image_npy_folder, exist_ok=True)

    # åˆ¤æ–­æ–‡ä»¶å¤¹æ˜¯ä¸æ˜¯ç©ºçš„
    if len(os.listdir(image_npy_folder)) != 0:
        # send_email(f"è¾“å…¥{output_folder}æ˜¯å·²ç»ç”Ÿæˆè¿‡äº†ï¼Œæ— éœ€é‡å¤è¾“å…¥ï¼ï¼ï¼")
        print(f"è¾“å…¥æ–‡ä»¶å¤¹{output_folder}æ˜¯å·²ç»ç”Ÿæˆè¿‡äº†ï¼Œæ— éœ€é‡å¤è¾“å…¥ï¼ï¼ï¼")
        # åˆ é™¤æ–‡ä»¶å¤¹
        os.removedirs(image_tif_folder)
        return
        raise ValueError("è¾“å…¥æ–‡ä»¶å¤¹æ˜¯å·²ç»ç”Ÿæˆè¿‡äº†ï¼Œæ— éœ€é‡å¤è¾“å…¥ï¼ï¼ï¼")

    # è£å‰ªå›¾ç‰‡å’Œæ ‡ç­¾
    for file in os.listdir(image_folder):
        if file.endswith(tif_shuffix):
            print("æ­£åœ¨å¤„ç†{}.........".format(file))
            crop_with_repetition_and_convert_delete(os.path.join(image_folder, file), image_tif_folder, 
                                                    crop_size, repetition_rate, image_npy_folder, shuffix=shuffix, skip_log=skip_log, resolution=resolution)


def normalize_dataset(stack_folder, max_value = [], min_value = []):
    max_value = np.asarray(max_value, dtype=np.float32)
    min_value = np.asarray(min_value, dtype=np.float32)
    range_val = max_value - min_value
    for file in tqdm(os.listdir(stack_folder)):
        if file.endswith(".npy"):
            # å¯¹ [h, w, c]çš„channelè¿›è¡Œå½’ä¸€åŒ–å¤„ç†
            npy_data = np.load(os.path.join(stack_folder, file)) # åŠ è½½çŸ©é˜µ (h,w,c)
            # å¯¹ [h, w, c]çš„channelè¿›è¡Œå½’ä¸€åŒ–å¤„ç†
            # TODO: è¿™é‡Œçš„æœ€åŽä¸€ä¸ªç»´åº¦ä¸è¿›è¡Œå½’ä¸€åŒ–å¤„ç†, CSMçš„é—®é¢˜
            npy_data = (npy_data - min_value[np.newaxis, np.newaxis, :]) / range_val[np.newaxis, np.newaxis, :]
            # for i in range(npy_data.shape[-1]):
            #     npy_data[:, :, i] = (npy_data[:, :, i]-min_value[i])/(max_value[i]-min_value[i])
            np.save(os.path.join(stack_folder, file), npy_data) # å¯¹å…¶é‡æ–°å†™å…¥

def get_band_statistics(
    base_folder: str,
    input_folders_name: List[str],
    json_path: Dict[str, Dict] = 'None',
    ignore_case: bool = True
) -> Tuple[List[float], List[float], List[float], List[float]]:
    """
    æ ¹æ®æ–‡ä»¶å¤¹ç»“æž„å’Œæ³¢æ®µé¡ºåºæå–ç»Ÿè®¡ä¿¡æ¯
    
    Args:
        json_data (Dict): åŒ…å«ç»Ÿè®¡ä¿¡æ¯çš„JSONæ•°æ®ç»“æž„
        base_folder (str): åŽŸå§‹æ•°æ®æ ¹ç›®å½•è·¯å¾„
        input_folders_name (List[str]): æŒ‰ä¼˜å…ˆçº§æŽ’åºçš„æ–‡ä»¶å¤¹ç»“æž„åˆ—è¡¨
        ignore_case (bool): æ˜¯å¦å¿½ç•¥è·¯å¾„å¤§å°å†™ï¼Œé»˜è®¤ä¸ºTrue
    
    Returns:
        Tuple[List[float], List[float], List[float], List[float]]: 
        (max_values, min_values, means, stds)
    
    Example:
        >>> maxs, mins, means, stds = get_band_statistics(
        ...     json_data,
        ...     r"D:\GLCM\Meiju1\Stack\split",
        ...     ["RGB", "Vegetation-Index/band8to11"],
        ...     ignore_case=True
        ... )
    """
    if os.path.exists(json_path):
        with open(json_path, 'r') as f:
            json_data = json.load(f)
        print(f"å·²åŠ è½½åŽ†å²è®°å½•ï¼š{len(json_data)} æ¡")

    def normalize_path(path: str) -> str:
        """è·¯å¾„è§„èŒƒåŒ–å¤„ç†"""
        path = path.replace('\\', '/')
        return path.lower() if ignore_case else path

    # æž„å»ºè·¯å¾„åŒ¹é…å­—å…¸
    search_patterns = {}
    for folder in input_folders_name:
        full_path = normalize_path(os.path.join(base_folder, folder))
        search_patterns[full_path] = folder

    # æŒ‰æ–‡ä»¶å¤¹ç»“æž„æ”¶é›†æ³¢æ®µä¿¡æ¯
    folder_bands = defaultdict(list)
    for key in json_data.keys():
        try:
            # åˆ†è§£è·¯å¾„å’Œæ³¢æ®µä¿¡æ¯
            dir_part = normalize_path(os.path.dirname(key))
            band_str = key.split("-band")[-1]
            band_num = int(''.join(filter(str.isdigit, band_str)))
            
            # åŒ¹é…æ–‡ä»¶å¤¹ç»“æž„
            matched_folder = None
            for pattern in search_patterns:
                if pattern in dir_part:
                    matched_folder = search_patterns[pattern]
                    break
            
            if matched_folder:
                folder_bands[matched_folder].append( (band_num, key) )
                
        except (IndexError, ValueError) as e:
            print(f"[Warning] è·³è¿‡æ— æ•ˆé”®å€¼: {key} ({str(e)})")
            continue

    # æŒ‰è¾“å…¥é¡ºåºå’Œæ³¢æ®µå·æŽ’åº
    ordered_results = []
    for folder in input_folders_name:
        if folder not in folder_bands:
            print(f"[Warning] æ–‡ä»¶å¤¹æœªæ‰¾åˆ°æ•°æ®: {folder}")
            continue
            
        # æŒ‰è‡ªç„¶æ•°æŽ’åºæ³¢æ®µ
        sorted_bands = sorted(folder_bands[folder], key=lambda x: x[0])
        
        # éªŒè¯æŽ’åºç»“æžœ
        band_nums = [b[0] for b in sorted_bands]
        if band_nums != sorted(band_nums):
            print(f"[Warning] éžè¿žç»­æ³¢æ®µå·: {folder} - {band_nums}")
        
        ordered_results.extend( [json_data[b[1]] for b in sorted_bands] )

    # æå–ç»Ÿè®¡ä¿¡æ¯
    max_values = [item["max"] for item in ordered_results]
    min_values = [item["min"] for item in ordered_results]
    # means = [item["mean"] for item in ordered_results]
    # stds = [item["std"] for item in ordered_results]

    # return max_values, min_values, means, stds
    return max_values, min_values

def change_future_data(folder, band_index):
    band_index -= 1  # å®žé™…æŒ‡å®šæ˜¯ä»Ž1å¼€å§‹,åœ¨ä»£ç ä¸­æ˜¯ä»Ž0å¼€å§‹
    for file in os.listdir(folder):
        file_path = os.path.join(folder, file)
        print(file_path)
        data = np.load(file_path, mmap_mode='c')
        print(data.shape)
        band_data = data[:,:,band_index-1]
        print(band_data*(85-1)+1)
        exit()

def process_label_images(input_folder, output_folder):
    """
    å¤„ç†æ–‡ä»¶å¤¹ä¸­çš„ç°åº¦ PNG æ ‡ç­¾å›¾åƒã€‚

    Args:
        input_folder (str): åŒ…å«åŽŸå§‹ PNG æ ‡ç­¾å›¾çš„æ–‡ä»¶å¤¹è·¯å¾„ã€‚
        output_folder (str): ä¿å­˜å¤„ç†åŽçš„ PNG æ ‡ç­¾å›¾çš„æ–‡ä»¶å¤¹è·¯å¾„ã€‚
    """
    # åˆ›å»ºè¾“å‡ºæ–‡ä»¶å¤¹ï¼ˆå¦‚æžœä¸å­˜åœ¨ï¼‰
    os.makedirs(output_folder, exist_ok=True)

    # éåŽ†è¾“å…¥æ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰æ–‡ä»¶
    for filename in tqdm(os.listdir(input_folder), unit="files", ncols=100):
        if filename.lower().endswith('.png'):
            input_path = os.path.join(input_folder, filename)
            output_path = os.path.join(output_folder, filename)

            try:
                # æ‰“å¼€å›¾åƒå¹¶ç¡®ä¿æ˜¯ç°åº¦å›¾ (Læ¨¡å¼)
                img = Image.open(input_path).convert('L')
                img_array = np.array(img)

                # æ£€æŸ¥åƒç´ å€¼èŒƒå›´æ˜¯å¦åœ¨ 0-7 å†… (å¯é€‰ï¼Œç”¨äºŽéªŒè¯)
                # if np.max(img_array) > 7 or np.min(img_array) < 0:
                #     print(f"Warning: {filename} contains pixel values outside the expected 0-7 range.")

                # åˆ›å»ºä¸€ä¸ªç”¨äºŽå­˜æ”¾å¤„ç†ç»“æžœçš„æ–°æ•°ç»„ï¼Œåˆå§‹åŒ–ä¸ºåŽŸæ•°ç»„çš„å‰¯æœ¬
                processed_array = img_array.copy()

                # è§„åˆ™ 1: å°†å€¼ä¸º 0 çš„åœ°æ–¹æ”¹ä¸º 255
                processed_array[img_array == 0] = 255

                # è§„åˆ™ 2: å°†å€¼ä¸º 1 åˆ° 7 çš„åœ°æ–¹å€¼å‡åŽ» 1
                # ä½¿ç”¨å¸ƒå°”ç´¢å¼•é€‰æ‹©éœ€è¦ä¿®æ”¹çš„åƒç´ 
                mask_1_to_7 = (img_array >= 1) & (img_array <= 7)
                processed_array[mask_1_to_7] = img_array[mask_1_to_7] - 1

                # å°† NumPy æ•°ç»„è½¬æ¢å›ž PIL å›¾åƒï¼Œå¹¶ç¡®ä¿æ•°æ®ç±»åž‹æ­£ç¡® (uint8)
                processed_img = Image.fromarray(processed_array.astype(np.uint8))

                # ä¿å­˜å¤„ç†åŽçš„å›¾åƒ
                processed_img.save(output_path)
                # print(f"Processed and saved {filename} to {output_folder}")

            except Exception as e:
                print(f"Error processing {filename}: {e}")

def create_none_severity_label(input_folder, output_folder):
    """
    å¤„ç†æ–‡ä»¶å¤¹ä¸­çš„ç°åº¦ PNG æ ‡ç­¾å›¾åƒï¼Œåº”ç”¨ç¬¬äºŒä¸ªè½¬æ¢è§„åˆ™ã€‚

    è§„åˆ™:
    - 3 å’Œ 4 éƒ½å˜ä¸º 3
    - 5 å˜ä¸º 4
    - 6 å˜ä¸º 5

    Args:
        input_folder (str): åŒ…å«åŽŸå§‹ PNG æ ‡ç­¾å›¾çš„æ–‡ä»¶å¤¹è·¯å¾„ã€‚
        output_folder (str): ä¿å­˜å¤„ç†åŽçš„ PNG æ ‡ç­¾å›¾çš„æ–‡ä»¶å¤¹è·¯å¾„ã€‚
    """
    # åˆ›å»ºè¾“å‡ºæ–‡ä»¶å¤¹ï¼ˆå¦‚æžœä¸å­˜åœ¨ï¼‰
    os.makedirs(output_folder, exist_ok=True)

    print(f"Creating none severity label from '{input_folder}' to '{output_folder}'...")

    # éåŽ†è¾“å…¥æ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰æ–‡ä»¶
    for filename in tqdm(os.listdir(input_folder), unit="files", ncols=100):
        if filename.lower().endswith('.png'):
            input_path = os.path.join(input_folder, filename)
            output_path = os.path.join(output_folder, filename)

            try:
                # æ‰“å¼€å›¾åƒå¹¶ç¡®ä¿æ˜¯ç°åº¦å›¾ (Læ¨¡å¼)
                img = Image.open(input_path).convert('L')
                img_array = np.array(img)

                # åˆ›å»ºä¸€ä¸ªç”¨äºŽå­˜æ”¾å¤„ç†ç»“æžœçš„æ–°æ•°ç»„ï¼Œåˆå§‹åŒ–ä¸ºåŽŸæ•°ç»„çš„å‰¯æœ¬
                processed_array = img_array.copy()

                # è§„åˆ™ 1: å°†å€¼ä¸º 3 æˆ– 4 çš„åœ°æ–¹éƒ½å˜ä¸º 3
                processed_array[(img_array == 3) | (img_array == 4)] = 3

                # è§„åˆ™ 2: å°†å€¼ä¸º 5 æˆ– 6 çš„åœ°æ–¹å€¼å‡åŽ» 1 (5->4, 6->5)
                # ä½¿ç”¨å¸ƒå°”ç´¢å¼•é€‰æ‹©éœ€è¦ä¿®æ”¹çš„åƒç´ 
                mask_5_to_6 = (img_array >= 5) & (img_array <= 6)
                processed_array[mask_5_to_6] = img_array[mask_5_to_6] - 1

                # å°† NumPy æ•°ç»„è½¬æ¢å›ž PIL å›¾åƒï¼Œå¹¶ç¡®ä¿æ•°æ®ç±»åž‹æ­£ç¡® (uint8)
                # æ³¨æ„ï¼šè¿™é‡Œçš„åƒç´ å€¼èŒƒå›´ä¼šæ˜¯ 0-6 (æ¥è‡ªæ—§çš„ 1-7 å’Œæ–°çš„ 5-6) ä»¥åŠ 3 (æ¥è‡ªæ—§çš„ 3/4)
                # æœ€ç»ˆèŒƒå›´ä¼šæ˜¯ 0-6 åŠ ä¸Šå¯èƒ½å­˜åœ¨çš„å…¶ä»–æœªä¿®æ”¹çš„åƒç´ å€¼
                processed_img = Image.fromarray(processed_array.astype(np.uint8))

                # ä¿å­˜å¤„ç†åŽçš„å›¾åƒ
                processed_img.save(output_path)
                # print(f"  Processed and saved {filename}")

            except Exception as e:
                print(f"  Error processing {filename}: {e}")
        else:
             print(f"  Skipping non-PNG file: {filename}")
    print("Create none severity label complete.")


if __name__ == '__main__':

    base_folder = r"F:/Rice2024/Meiju1/Split_Stretch"  # æ•°æ®æº
    output_base_folder = r"D:/Rice2024/Meiju1/Datasets/Samples"  # å½’ä¸€åŒ–åŽçš„æ•°æ®é›†ä½ç½®
    output_stack_folder = r"G:/Rice2024/Meiju1/Datasets/Stack_Norm_All"  # æœ€ç»ˆå½’ä¸€åŒ–åŽçš„å †å æ•°æ®é›†ä½ç½®
    output_label_folder = r"F:/Rice2024/Meiju1/Labels/Temp" # Labels ä½ç½®
    output_label_severity = r"F:/Rice2024/Meiju1/Labels/Rice_Lodging_Severity"
    ouptut_label_none_severity = r"F:/Rice2024/Meiju1/Labels/Rice_Lodging_None_Severity"

    black_val = 1e-34
    resolution = (84765, 70876)

    # åˆ†æ–‡ä»¶å¤¹, å¯¹åº”è¾“å…¥å’Œè¾“å‡ºçš„æ–‡ä»¶å¤¹
    input_folders_name = [
        r'1_RGB-3',
        r'2_CIs-10\B4-B7',
        r'2_CIs-10\B8-B11',
        r'2_CIs-10\B12-B13',
        r'3_MSI-4',
        r'4_VIs-13\B18-B21',
        r'4_VIs-13\B22-B25',
        r'4_VIs-13\B26-B28',
        r'4_VIs-13\B29-B30',
        r'5_R-GLCM-8\B31-B34',
        r'5_R-GLCM-8\B35-B38',
        r'6_G-GLCM-8\B39-B42',
        r'6_G-GLCM-8\B43-B46',
        r'7_B-GLCM-8\B47-B50',
        r'7_B-GLCM-8\B51-B54',
        r"8_CHM-1"
    ]
    # ä¸åŒæ–‡ä»¶å¯¹åº”çš„å¿½ç•¥å€¼, TODO: éœ€è¦è¿›ä¸€æ­¥ç¡®å®š, å…ˆä¸ç®¡
    # ignore_values = {
    #     r'RGB' : 0,
    #     r'Multi-spectral' : 1e-34,
    #     r"band8to11": 1e-34,
    #     r'band12to15': 1e-34,
    #     r"band16to18": 1e-34,
    #     r'band19to20': 1e-34,
    #     r'band21to24': 0,
    #     r'band25to28': 0,
    #     r'band29to32': 0,
    #     r'band33to36': 0,
    #     r'band37to40': 0,
    #     r'band41to44': 0,
    #     r'DSM' : -9999,
    # }
    ignore_value = 1e-34
    
    channel_mapping = {
        r'1_RGB-3': [0, 1, 2],
        r'2_CIs-10\B4-B7': [3, 4, 5, 6],
        r'2_CIs-10\B8-B11': [7, 8, 9, 10],
        r'2_CIs-10\B12-B13': [11, 12],
        r'3_MSI-4': [13, 14, 15, 16],
        r'4_VIs-13\B18-B21': [17, 18, 19, 20],
        r'4_VIs-13\B22-B25': [21, 22, 23, 24],
        r'4_VIs-13\B26-B28': [25, 26, 27],
        r'4_VIs-13\B29-B30': [28, 29],
        r'5_R-GLCM-8\B31-B34': [30, 31, 32, 33],
        r'5_R-GLCM-8\B35-B38': [34, 35, 36, 37],
        r'6_G-GLCM-8\B39-B42': [38, 39, 40, 41],
        r'6_G-GLCM-8\B43-B46': [42, 43, 44, 45],
        r'7_B-GLCM-8\B47-B50': [46, 47, 48, 49],
        r'7_B-GLCM-8\B51-B54': [50, 51, 52, 53],
        r"8_CHM-1": [54],
    }




    # ç‰¹å¾é€šé“æå–
    features_to_process = [r'1_RGB-3', 
                           r'2_CIs-10\B4-B7', 
                           r"2_CIs-10\B8-B11",
                           r'2_CIs-10\B12-B13', 
                           r'3_MSI-4', 
                           r"4_VIs-13\B18-B21",
                           r"4_VIs-13\B22-B25",
                           r'4_VIs-13\B26-B28', 
                           r'4_VIs-13\B29-B30',
                           r"8_CHM-1",
                           ]
    features_output_dir = r'D:/Rice2024/Meiju1/Datasets/Stack_Norm_RGB-CIs -VIs-CHM' # ç‰¹å¾æå–è¾“å‡ºæ–‡ä»¶å¤¹é€šé“

    input_folders = [] # è¾“å…¥æ–‡ä»¶å¤¹ï¼Œæ¯ä¸ªç‰¹å¾å¯¹åº”ä¸€ä¸ª
    # for i, folder in enumerate(input_folders_name):
    #     input_folders.append(os.path.join(base_folder, folder))
    output_folders = [] # è¾“å‡ºæ–‡ä»¶å¤¹ï¼Œæ¯ä¸ªç‰¹å¾å¯¹åº”ä¸€ä¸ª
    # for i, folder in enumerate(input_folders_name):
    #     output_folders.append(os.path.join(output_base_folder, folder))
    #     os.makedirs(output_folders[i], exist_ok=True)

    # æ ‡ç­¾å­˜æ”¾ä½ç½®
    label_folder = r"F:/Rice2024/Meiju1/Labels-shp" # TODO: è¿˜æ²¡ç¡®å®šå¥½
    label_name = r"Meiju1_2_Lingtangkou_v5.tif" # æ ‡ç­¾åå­—
    label_path = os.path.join(label_folder, label_name)
    train_val_test_ratio = (0.6, 0.2, 0.2)
    crop_size = 640
    repetition_rate = 0.1
    threshold = 0.9
    skip_log = "logs/Meiju1_All_55.json" # è·³è¿‡æ–‡ä»¶è·¯å¾„, ç”¨äºŽè£å‰ªåŽ é€‚å½“è·³è¿‡é»‘è‰²èƒŒæ™¯çš„å›¾ç‰‡
    normalize_log = "logs/Meiju1_All_55_Normalized.json" # å½’ä¸€åŒ–æ–‡ä»¶è·¯å¾„ï¼Œç”¨äºŽå›¾åƒå½’ä¸€åŒ–ï¼Œè®°å½•å‚æ•°æ–‡ä»¶
    normalize_excel_output_path = "logs/Meiju1_All_55_Normalized.xlsx" # å½’ä¸€åŒ–æ–‡ä»¶è·¯å¾„ï¼Œç”¨äºŽå›¾åƒå½’ä¸€åŒ–ï¼Œè®°å½•å‚æ•°æ–‡ä»¶

    parser = argparse.ArgumentParser()
    parser.add_argument('--run', type=str, default="create")
    args = parser.parse_args()

    image_npy_folder = "Image_Npy"  # è½¬æ¢æˆ.npyæ–‡ä»¶çš„ä¸‹çº§æ–‡ä»¶å¤¹åå­—
    image_tif_folder = "Image_Tif"  # è½¬æ¢æˆ.tifæ–‡ä»¶çš„ä¸‹çº§æ–‡ä»¶å¤¹åå­—

    start_time = datetime.now()

    if args.run == "get_input_folders":
        folders = []
        for dir, _, files in os.walk(base_folder):
            # print(files)
            if len(files):
                folders.append(dir)

        # print(folders[1:])
        for folder in folders:
            print('r'+'\''+folder+'\''+',')
        print("æ³¨æ„ä¸‹é€šé“çš„é¡ºåºä½ç½®ðŸ˜Š")

    elif args.run == "create_preprocess": # ç”Ÿæˆè·³è¿‡è®°å½•
        for input_image_folder, output_image_folder  in zip(input_folders, output_folders):
        # å…ˆè£å‰ªåŽç”Ÿæˆ
            if 'RGB' in input_image_folder:
                print(f'{skip_log}è·³è¿‡è®°å½•ç”Ÿæˆ....')
                crop_with_repetition_and_save_skip_log(os.path.join(input_image_folder, "Split_Stretch_RGB.tif"),
                                                       os.path.join(output_image_folder, "skip_record_tif_temp"), crop_size=crop_size,
                                                       repetition_rate=repetition_rate, skip_log=skip_log, threshold=threshold, resolution=resolution, black_val=black_val)
            else:
                send_email('ç”Ÿæˆè·³è¿‡è®°å½•å¤±è´¥...')
                raise "Not RGB"

    elif args.run == "create":  # åˆ‡åˆ†æ•°æ®é›†
        print(input_folders)
        for input_image_folder, output_image_folder  in zip(input_folders, output_folders):
            create_dataset_image(input_image_folder, output_image_folder, resolution=resolution, crop_size=640, repetition_rate=repetition_rate,
                                 skip_log=skip_log)
        send_email(f'numpyæ•°æ®é›†åˆ¶ä½œå®Œæˆ, ç”¨æ—¶:{datetime.now() - start_time}', "æ•°æ®é›†åˆ¶ä½œå®Œæˆ..")  

    elif args.run == "move":  # æŠŠnpyæ–‡ä»¶å¤¹ç§»åŠ¨åˆ°çˆ¶æ–‡ä»¶å¤¹ä¸­
        npy_folders = []
        tif_folders = []
        # åŠ ä¸ŠNpyè·¯å¾„
        for i, folder in enumerate(output_folders):
            npy_folders.append(os.path.join(folder, image_npy_folder))
            tif_folders.append(os.path.join(folder, image_tif_folder))
        print(output_folders)
        print(npy_folders)

        for target_folder, source_folder in zip(output_folders, npy_folders):
            for file in tqdm(os.listdir(source_folder), desc=f"Move {os.path.basename(source_folder)} Files"):
                shutil.move(os.path.join(source_folder, file), os.path.join(target_folder, file))

        # åˆ é™¤å¯¹åº”çš„Folder
        for npy_folder, tif_folder in zip(npy_folders, tif_folders):
            os.removedirs(npy_folder)
            if os.path.exists(tif_folder):
                os.removedirs(tif_folders)
            print(f"Successfully removed {npy_folder} and {tif_folder}")
            # remove_folder(folder)

    elif args.run == "stack":  # å †å æ•°æ®é›†
        # åŠ ä¸ŠNpyè·¯å¾„
        # for i, folder in enumerate(output_folders):
        #     output_folders[i] = os.path.join(folder, image_npy_folder)
        print(output_folders)
        stack_npy_files(output_folders, output_stack_folder)
        send_email(f'stackæ•°æ®é›†åˆ¶ä½œå®Œæˆ, ç”¨æ—¶:{datetime.now() - start_time}', "æ•°æ®é›†åˆ¶ä½œå®Œæˆ..")  

    elif args.run == "label":
        create_dataset_image(label_folder, output_label_folder, resolution=resolution,crop_size=640, repetition_rate=repetition_rate,
                             tif_shuffix=label_name, shuffix=".png", skip_log=skip_log)
        send_email(f"Labelæ•°æ®é›†åˆæˆ, ç”¨æ—¶: {datetime.now() - start_time}")

    elif args.run == "label_severity":
        # ç”ŸæˆåŒºåˆ†å’Œä¸åŒºåˆ†å€’ä¼ç¨‹åº¦çš„æ ‡ç­¾å›¾ç‰‡
        process_label_images(output_label_folder, output_label_severity)
        create_none_severity_label(output_label_severity, ouptut_label_none_severity)

    elif args.run == "calc_normlize": # è®¡ç®—èŽ·å–å½’ä¸€åŒ–ä¿¡æ¯
        for folder in input_folders:
            for file in os.listdir(folder):
                # if files.endswith(".tif"):
                if file.startswith("Split_Stretch_") and file.endswith(".tif") and "CHM" not in file:
                    base_name = os.path.basename(folder)
                    print(f'{base_name}: {file}')
                    calc_mean_and_std(os.path.join(folder, file), label_path=label_path, calc_logs=normalize_log, ignore_value=ignore_value, excel_output_path=normalize_excel_output_path)
        send_email("è®¡ç®—å½’ä¸€åŒ–æŒ‡æ•°å®Œæˆ")

    elif args.run == 'normlize_print':  # æ‰“å°å½’ä¸€åŒ–ä¿¡æ¯
        max_vals, min_vals = get_band_statistics(base_folder, input_folders_name, json_path=normalize_log)
        print("Max values: ", max_vals)
        print("Min values: ", min_vals)
        # print("Means: ", means)
        # print("Stds: ", stds)
        print("bands num", len(max_vals))

    elif args.run == 'normlize': # è¿›è¡Œå½’ä¸€åŒ–
        max_vals, min_vals = get_band_statistics(base_folder, input_folders_name, json_path=normalize_log)
        normalize_dataset(output_stack_folder, max_value=max_vals, min_value=min_vals)
        send_email("å½’ä¸€åŒ–è½¬æ¢å®Œæˆ")

    elif args.run == "split":  # åˆ‡åˆ†æ•°æ®é›†æˆ train, val, test
        train_ratio, valid_ratio, test_ratio = train_val_test_ratio
        output_label_folder = os.path.join(output_label_folder, image_npy_folder)
        # é‡å‘½åæ–‡ä»¶
        rename_files(image_folder=output_stack_folder, label_folder=output_label_folder, label_end_with='.png')
        # åˆ‡åˆ†æ•°æ®é›†
        split_dataset(output_stack_folder, output_label_folder, train_ratio=train_ratio, val_ratio=valid_ratio, test_ratio=test_ratio, labels_suffix=".png")
        send_email(f"åˆ‡åˆ†æ•°æ®é›†, ç”¨æ—¶: {datetime.now() - start_time}")
    
    elif args.run == "feature":   # æå–æŒ‡å®šçš„ç‰¹å¾åˆ°æ–°æ–‡ä»¶å¤¹ä¸Š
        # Define the base input directory to walk through
        base_input_folder = r"/data/Rice2024/ALL"
        # Define the base output directory for the extracted features
        base_output_folder = r'/data/Rice2024/RGB_Color_Spectra_Texture'

        # Define the features to process (same for all data subdirectories)
        features_to_process = [
            r'1_RGB-3',
            r'2_CIs-10\B4-B7',
            r'2_CIs-10\B8-B11',
            r'2_CIs-10\B12-B13',
            r'3_MSI-4',
            r'4_VIs-13\B18-B21',
            r'4_VIs-13\B22-B25',
            r'4_VIs-13\B26-B28',
            r'4_VIs-13\B29-B30',
            r'5_R-GLCM-8\B31-B34',
            r'5_R-GLCM-8\B35-B38',
            r'6_G-GLCM-8\B39-B42',
            r'6_G-GLCM-8\B43-B46',
            r'7_B-GLCM-8\B47-B50',
            r'7_B-GLCM-8\B51-B54',
            # r"8_CHM-1"
            ]

        print(f"--- Starting feature extraction across {base_input_folder} ---")
        print(f"Saving extracted features to base directory: {base_output_folder}")


        MAX_WORKERS = 24
        # Walk through all subdirectories starting from the base input folder
        # os.walk yields tuples (dirpath, dirnames, filenames)
        # dirpath is the current directory being walked (e.g., /root/datasets/ALL/train/scene1)
        # dirnames is a list of names of the subdirectories in dirpath
        # filenames is a list of names of the files in dirpath
        for dirpath, dirnames, filenames in os.walk(base_input_folder):
            # We are only interested in directories that actually contain files (data subdirectories)
            # This check prevents processing parent directories like /root/datasets/ALL/train or /root/datasets/ALL
            # unless they also happen to directly contain data files, which is less typical
            if filenames:
                print(f"\nProcessing data directory: {dirpath}")

                # Calculate the path of the current data directory relative to the base input folder
                # e.g., if dirpath is /root/datasets/ALL/train/scene1, relative_path will be train/scene1
                relative_path = os.path.relpath(dirpath, base_input_folder)

                # Construct the corresponding output subdirectory path by joining the base output folder
                # with the relative path.
                # e.g., os.path.join(/root/data_temp/CHM, train/scene1) -> /root/data_temp/CHM/train/scene1
                output_subdir = os.path.join(base_output_folder, relative_path)
                print(f"Saving features to: {output_subdir}")
                
                # Ensure the output directory structure exists before trying to save files into it
                # exist_ok=True prevents errors if the directory already exists
                os.makedirs(output_subdir, exist_ok=True)

                # # Call the function to split/extract features
                # # It takes the input directory (dirpath), channel mapping, output directory, and features list
                split_npy_files_threaded(dirpath, channel_mapping,
                                output_subdir, features_to_process, max_threads=MAX_WORKERS)

    elif args.run == "change_future":
        change_future_data(output_stack_folder, 10)

    elif args.run == "visualize":
        # print(input_folders)
        for folder in input_folders:
            # if "B4-B7" in folder:
            for file in os.listdir(folder):
                file_path = os.path.join(folder, file)
                print(file)
                # print(file)
                output_folder = folder.replace("F", "G")
                dataset = gdal.Open(file_path)
                bands = dataset.RasterCount
                for band_index in range(1, bands+1):
                    print(f"band index is {band_index}")
                    visualize_feature(file_path, label_path, ignore_value, band_index, output_folder)
                print(f"run one feature time is {datetime.now() - start_time}")


    elif args.run == "check":
        # Define the base input directory to walk through
        base_input_folder = r"/data/Rice2024/ALL"
        # Define the base output directory for the extracted features
        base_output_folder = r'/data/Rice2024/RGB_Color_Spectra_Texture'

        check_folder = "train/data"

        input_folder = os.path.join(base_input_folder, check_folder)
        output_folder = os.path.join(base_output_folder, check_folder)

        check_channels = list(range(0, 54))
        print("channels number is", len(set(check_channels)))
        print(check_channels)
        for i, file in enumerate(os.listdir(input_folder)):
            all_file_path = os.path.join(input_folder, file)
            check_file_path = os.path.join(output_folder, file)
            all_file_data = np.load(all_file_path, mmap_mode='c')
            check_file_data = np.load(check_file_path, mmap_mode='c')
            print(i, all_file_data[:,:,check_channels].shape, check_file_data.shape)
            assert np.array_equal(all_file_data[:,:,check_channels], check_file_data)
            if i == 100:
                break
            # for i in check_channels:
                # assert np.array_equal(all_file_data[i], check_file_data[i])
        print("check successfully..")

    print('run time is {}'.format(datetime.now()-start_time))
    






